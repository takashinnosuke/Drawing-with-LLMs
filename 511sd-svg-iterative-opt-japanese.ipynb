{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":89659,"databundleVersionId":11735795,"sourceType":"competition"},{"sourceId":224423433,"sourceType":"kernelVersion"},{"sourceId":230023475,"sourceType":"kernelVersion"},{"sourceId":230023480,"sourceType":"kernelVersion"},{"sourceId":4527,"sourceType":"modelInstanceVersion","modelInstanceId":3319,"modelId":971},{"sourceId":263093,"sourceType":"modelInstanceVersion","modelInstanceId":225001,"modelId":164716},{"sourceId":289299,"sourceType":"modelInstanceVersion","modelInstanceId":247861,"modelId":269379},{"sourceId":289308,"sourceType":"modelInstanceVersion","modelInstanceId":247869,"modelId":269387}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stable Diffusion -> SVG\n\n\n## reference\nSimple SD -> SVG Iterative opt(https://www.kaggle.com/code/jiazhuang/new-metric-simple-sd-svg-iterative-optimize)\n\n### 主要な流れ\n- 画像生成：テキスト説明からビットマップ画像を作成するためにStable Diffusionモデルを利用\n- SVG変換：ビットマップ画像を最適化されたSVG形式に変換。ファイルサイズ制限に収まるように最適化\n- 評価：生成されたSVGの品質を特有の基準(OCRスコアと美的スコアの積)に従って評価し最適なSVGを選択","metadata":{"_uuid":"619af753-db66-43b5-a016-d8e39c7e2050","_cell_guid":"b76a1a0e-89e3-4d27-9072-48377f625073","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#| default_exp core","metadata":{"_uuid":"154e55cc-0635-4d0f-9713-715358aea677","_cell_guid":"b4fc3c27-e82f-4b6a-8f66-2227f5be16d4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:55:08.344239Z","iopub.execute_input":"2025-05-10T16:55:08.344544Z","iopub.status.idle":"2025-05-10T16:55:08.348072Z","shell.execute_reply.started":"2025-05-10T16:55:08.344503Z","shell.execute_reply":"2025-05-10T16:55:08.347301Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 1.準備","metadata":{}},{"cell_type":"markdown","source":"### 1.1 初期設定とライブラリのインポート\n- 必要なライブラリ（PyTorch、Diffusers、Transformers、OpenCV、Pillowなど）をインポートします。\n- Kaggle Hubから、SVG画像の忠実度を評価するための`metric`パッケージをインポートします。https://www.kaggle.com/code/jiazhuang/new-metric-simple-sd-svg-iterative-optimize","metadata":{}},{"cell_type":"code","source":"#| export\n# 必要なライブラリをインポート\nimport kagglehub\n\nimport os\nimport io\nimport re\nimport random\nimport base64\nfrom io import BytesIO\n\nimport time\nfrom datetime import timedelta\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn.functional as F\n\nfrom IPython.display import SVG # SVG表示用\n\nfrom PIL import Image # 画像処理用\nimport cv2 # OpenCV 画像処理用\n\nfrom diffusers import StableDiffusionPipeline, DDIMScheduler # Stable Diffusionモデル用\nfrom transformers import AutoProcessor, AutoModel # Hugging Face Transformersモデル用\n\n# Kaggle HubからSVG画像忠実度評価用のメトリックパッケージをインポート\nmetric = kagglehub.package_import('jiazhuang/svg-image-fidelity')","metadata":{"_uuid":"3e514dce-fb0e-44aa-980f-671391b99a87","_cell_guid":"b57893ea-fb8b-49e0-a127-557a141ad911","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:55:12.130338Z","iopub.execute_input":"2025-05-10T16:55:12.130693Z","iopub.status.idle":"2025-05-10T16:57:16.295180Z","shell.execute_reply.started":"2025-05-10T16:55:12.130663Z","shell.execute_reply":"2025-05-10T16:57:16.294412Z"}},"outputs":[{"name":"stdout","text":"Installing python dependencies for Package 'kagglehub_package_jiazhuang_svg_image_fidelity_12', logging progress to '/tmp/kagglehub-package-dependencies-install-6nt_tr1c.txt'.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb613658d3ad43b99c6219343661e03f"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### 1.2　ハイパーパラメータ管理 \n- `CFG`クラスで、モデルのパス、画像生成パラメータ、SVG変換パラメータ、評価用パラメータなど、ノートブック全体で使用する設定値を一元管理しています。","metadata":{}},{"cell_type":"code","source":"#| export\n# 設定値を管理するクラス\nclass CFG:\n    # デバイス設定\n    _PREFERRED_DEVICE_IF_CUDA = \"cuda:1\"\n    device = _PREFERRED_DEVICE_IF_CUDA if torch.cuda.is_available() else \"cpu\"\n\n    # 一般設定\n    random_seed = 42 # 乱数シード\n\n    # Stable Diffusionモデル設定\n    stable_diffusion_model_name = \"stabilityai/stable-diffusion-v2/pytorch/1/1\" # 使用するモデル名\n    sd_torch_dtype = torch.float16 # Stable Diffusionのデータ型（メモリ削減と高速化のため半精度）\n    sd_safety_checker = None  # セーフティチェッカーを無効化（速度向上のため）\n\n    # ビットマップ生成パラメータ (generate_bitmap関数および一般用途)\n    bitmap_prompt_prefix = \"Simple, classic image of\" # プロンプト接頭辞\n    bitmap_prompt_suffix = \"with flat color blocks, beautiful, minimal details, solid colors only\" # プロンプト接尾辞\n    bitmap_negative_prompt = \"lines, framing, hatching, background, textures, patterns, details, outlines\" # ネガティブプロンプト\n    bitmap_num_inference_steps_default = 20  # generate_bitmapのデフォルト推論ステップ数\n    bitmap_guidance_scale_default = 15       # generate_bitmapのデフォルトガイダンススケール\n\n    # ビットマップからSVGへの変換パラメータ (bitmap_to_svg_layered関数用)\n    svg_max_size_bytes = 10000 # SVGファイルの最大バイト数\n    svg_resize = True # SVG変換前にリサイズするかどうか\n    svg_target_size = (384, 384) # リサイズする場合のターゲットサイズ\n    svg_adaptive_fill = True # SVG生成時に適応的に要素を配置・単純化してスペースを埋めるか\n    svg_num_colors_default = None # 量子化する色の数。Noneの場合、bitmap_to_svg_layered内の適応ロジックを使用\n\n    # bitmap_to_svg_layered内の適応的な色数ロジック用パラメータ\n    svg_num_colors_small_image_threshold = 65536  # 例: 256x256ピクセル\n    svg_num_colors_medium_image_threshold = 262144 # 例: 512x512ピクセル\n    svg_num_colors_for_small_image = 8  # 小さい画像用の色数\n    svg_num_colors_for_medium_image = 12 # 中程度の画像用の色数\n    svg_num_colors_for_large_image = 16 # 大きい画像用の色数\n    \n    # extract_features_by_scale用パラメータ (bitmap_to_svg_layered内で使用)\n    svg_contour_min_area = 20 # 輪郭抽出時の最小面積（これ以下の面積の輪郭は無視）\n    svg_approx_poly_dp_epsilon_factor = 0.02 # 輪郭近似（単純化）の際のepsilon係数\n\n    # AESおよびOCRスコア計算パラメータ (get_aes_and_ocr_score関数用)\n    aes_ocr_seed = 33 # 美的スコア・OCRスコア計算時の乱数シード\n    aes_ocr_jpeg_quality = 90 # JPEG圧縮品質\n\n    # Modelクラスのパラメータ\n    model_default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\" # デフォルトSVG\n    # これらはビットマップ生成パラメータと同じでも、モデル固有の調整に応じて異なっていても良い\n    model_prompt_prefix = \"Simple, classic image of\"\n    model_prompt_suffix = \"with flat color blocks, beautiful, minimal details, solid colors only\"\n    model_negative_prompt = \"lines, framing, hatching, background, textures, patterns, details, outlines\"\n    model_num_inference_steps = 25 # Modelクラス内での推論ステップ数\n    model_guidance_scale = 20      # Modelクラス内でのガイダンススケール\n    model_num_attempt = 3      # Modelクラス内での生成試行回数","metadata":{"_uuid":"053a4bee-41de-4f84-8d59-29bcd0d85e03","_cell_guid":"950e5060-23a5-4f05-9016-6bb6b6b7feb9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:57:30.737728Z","iopub.execute_input":"2025-05-10T16:57:30.738362Z","iopub.status.idle":"2025-05-10T16:57:30.744896Z","shell.execute_reply.started":"2025-05-10T16:57:30.738333Z","shell.execute_reply":"2025-05-10T16:57:30.743996Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### 1.3 評価指標を計算するヘルパー関数の定義\nコンペティションで使用される評価指標を計算するためのヘルパー関数群です。\n主に画像（ビットマップやSVGから変換されたPNG）と質問応答データを用いて、\nVQAスコア、美的スコア、OCRスコア、そしてそれらを統合した最終スコアを算出します。","metadata":{"_uuid":"c313a8db-21c5-42ae-b15e-bcd7b7eb3c03","_cell_guid":"46d9f1b2-93d5-4937-af40-5ed523374617","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import statistics #提出パッケージには含まれないため、ここでimport\n\n# 指定されたサイズに画像をリサイズする関数\ndef image_resize(image, size=(384, 384)): # 注意: target_sizeは一貫性があればCFGからも取得可能\n    return image.convert('RGB').resize(size)\n\n# ビットマップ画像のスコア（インスタンス単位）を計算する内部実装関数\n# VQAスコア、美的スコア、OCRスコア、およびそれらを統合したコンペティションスコアを返す\ndef bitmap_score_instance_impl(multiple_choice_qa, image, random_seed=CFG.random_seed): # CFG.random_seedを使用\n    rng = np.random.RandomState(random_seed) # 指定されたシードで乱数生成器を初期化\n    group_seed = rng.randint(0, np.iinfo(np.int32).max) # 評価用シードを生成\n    \n    # 画像処理（リサイズ）\n    image_processor = metric.ImageProcessor(image=image_resize(image), seed=group_seed).apply()\n    processed_image = image_processor.image.copy() # 処理済み画像を取得\n    \n    # QAデータ取得\n    questions = multiple_choice_qa['question']\n    choices = multiple_choice_qa['choices']\n    answers = multiple_choice_qa['answer']\n    \n    # 各スコアの計算\n    aesthetic_score = metric.aesthetic_evaluator.score(processed_image) # 美的スコア\n    vqa_score = metric.vqa_evaluator.score(questions, choices, answers, processed_image) # VQAスコア\n    \n    # OCRスコア計算用の画像処理（ランダムクロップ・リサイズ、JPEG圧縮）\n    image_processor.reset().apply_random_crop_resize().apply_jpeg_compression(quality=CFG.aes_ocr_jpeg_quality) # qualityはCFGから取得\n    ocr_score = metric.vqa_evaluator.ocr(image_processor.image) # OCRスコア\n    \n    # 最終的なインスタンススコアの計算 (VQAと美的スコアの調和平均にOCRスコアを乗算)\n    instance_score = metric.harmonic_mean(vqa_score, aesthetic_score, beta=0.3) * ocr_score\n    \n    return instance_score, vqa_score, ocr_score, aesthetic_score\n\n# ビットマップ画像のスコアを計算する関数 (単一または複数の画像に対応)\ndef bitmap_score_instance(multiple_choice_qa, image, random_seed=CFG.random_seed): # CFG.random_seedを使用\n    is_single = not isinstance(image, list) # 入力が単一画像かどうかを判定\n    if is_single:\n        # 単一画像の場合、リストに変換して統一的に処理\n        multiple_choice_qa = [multiple_choice_qa]\n        image = [image]\n\n    assert len(multiple_choice_qa) == len(image), \"QAデータと画像の数が一致しません\"\n\n    results = []\n    score_df_rows = []\n    for one_image, one_multiple_choice_qa in zip(image, multiple_choice_qa, strict=True):\n        # 各画像に対してスコア計算\n        instance_score, vqa_score, ocr_score, aesthetic_score = bitmap_score_instance_impl(\n            one_multiple_choice_qa, one_image, random_seed=random_seed # random_seedを渡す\n        )\n        results.append(instance_score)\n        score_df_rows.append([instance_score, vqa_score, ocr_score, aesthetic_score])\n\n    fidelity = statistics.mean(results) if results else 0.0 # 平均スコアを計算\n    score_df = pd.DataFrame(score_df_rows, columns=['competition_score', 'vqa_score', 'ocr_score', 'aesthetic_score'])\n    \n    if is_single:\n        # 単一画像の場合は辞書形式でスコアを返す\n        return score_df.iloc[0].to_dict()\n    else:\n        # 複数画像の場合は平均スコアと詳細スコアのDataFrameを返す\n        return float(fidelity), score_df","metadata":{"_uuid":"9e2c51d8-63c6-454c-b388-a57c0257e886","_cell_guid":"2755f594-998a-4e13-8821-d277abf18ba5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:57:33.614753Z","iopub.execute_input":"2025-05-10T16:57:33.615077Z","iopub.status.idle":"2025-05-10T16:57:33.623924Z","shell.execute_reply.started":"2025-05-10T16:57:33.615050Z","shell.execute_reply":"2025-05-10T16:57:33.622959Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#| export\n# SVGコンテンツから美的スコアとOCRスコアを取得する関数\ndef get_aes_and_ocr_score(svg_content_str):\n    \"\"\"\n    SVG文字列から美的スコアとOCRスコアを計算します。\n    Args:\n        svg_content_str (str): SVG形式の文字列。\n    Returns:\n        tuple: (美的スコア, OCRスコア)。\n    \"\"\"\n    # SVGをPNGに変換し、画像処理を実行 (シードはCFGから取得)\n    image_proc = metric.ImageProcessor(image=metric.svg_to_png(svg_content_str), seed=CFG.aes_ocr_seed).apply()\n    processed_img = image_proc.image.copy()\n    \n    aesthetic_val = metric.aesthetic_evaluator.score(processed_img) # 美的スコア計算\n    \n    # OCRスコア計算用の画像処理 (ランダムクロップ・リサイズ、JPEG圧縮。品質はCFGから取得)\n    image_proc.reset().apply_random_crop_resize().apply_jpeg_compression(quality=CFG.aes_ocr_jpeg_quality)\n    ocr_val = metric.vqa_evaluator.ocr(image_proc.image) # OCRスコア計算\n    \n    return aesthetic_val, ocr_val","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:57:36.256589Z","iopub.execute_input":"2025-05-10T16:57:36.256880Z","iopub.status.idle":"2025-05-10T16:57:36.261550Z","shell.execute_reply.started":"2025-05-10T16:57:36.256859Z","shell.execute_reply":"2025-05-10T16:57:36.260714Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 1.4 Stable Diffusionのロード\nStable DiffusionモデルをKaggle Hubからダウンロードし、パイプラインを初期化します。\n高速化のため、最適化されたスケジューラを使用し、半精度浮動小数点数(float16)でモデルをロードします。\nまた、セーフティチェッカーは無効化します。","metadata":{"_uuid":"5abe4608-ab8c-4b73-8789-c44ff1645ce2","_cell_guid":"60a71b0e-c4b6-4128-af07-6c8757bd58e0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#| export\n\n# GPUが使用されていることを確認 (CFGクラスで設定されたデバイスを使用)\nprint(f\"使用デバイス: {CFG.device}\")\n\n# Stable DiffusionモデルのパスをKaggle Hubから取得\nstable_diffusion_path = kagglehub.model_download(CFG.stable_diffusion_model_name)\n\n# 最適化されたDDIMスケジューラをロード\nscheduler = DDIMScheduler.from_pretrained(stable_diffusion_path, subfolder=\"scheduler\")\n\n# Stable Diffusionパイプラインをロード\n# 半精度(torch_dtype)を使用し、セーフティチェッカーを無効化(safety_checker=None)して高速化\npipe = StableDiffusionPipeline.from_pretrained(\n    stable_diffusion_path,\n    scheduler=scheduler,\n    torch_dtype=CFG.sd_torch_dtype,\n    safety_checker=CFG.sd_safety_checker\n)\n\n# モデルをGPU (またはCPU) に移動\npipe.to(CFG.device)","metadata":{"_uuid":"97e5dadd-521f-4241-b34f-bd1b35c902d4","_cell_guid":"61560fcc-fda7-4313-be56-777df29e59e7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:57:39.132393Z","iopub.execute_input":"2025-05-10T16:57:39.132741Z","iopub.status.idle":"2025-05-10T16:58:04.529628Z","shell.execute_reply.started":"2025-05-10T16:57:39.132712Z","shell.execute_reply":"2025-05-10T16:58:04.528714Z"}},"outputs":[{"name":"stdout","text":"使用デバイス: cuda:1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc86f8829e354df3abe31f8d6e78dd5b"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"StableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.31.0\",\n  \"_name_or_path\": \"/kaggle/input/stable-diffusion-v2/pytorch/1/1\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"image_encoder\": [\n    null,\n    null\n  ],\n  \"requires_safety_checker\": false,\n  \"safety_checker\": [\n    null,\n    null\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"DDIMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### 1.5 データのロード\nコンペティション用の学習データ（`train.csv`）と質問データ（`questions.parquet`）をロードします。\n質問データは、各画像IDに対応する質問、選択肢、回答のセットが含まれるように整形されます。","metadata":{"_uuid":"fc793161-f607-4a88-a8bb-5c7b23ea51f8","_cell_guid":"1061a2e5-0cdb-4608-b025-2da3908a71f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 提出パッケージには含まれないためここでimport\nimport json\nimport pandas as pd\n\n# このパスは動的に決定されるため、ハイパーパラメータではない\ndrawing_with_llms_path = kagglehub.competition_download('drawing-with-llms')\n\n# 学習データと質問データをロード\ntrain_df = pd.read_csv(f'{drawing_with_llms_path}/train.csv')\ntrain_question_df = pd.read_parquet(f'{drawing_with_llms_path}/questions.parquet')\n\n\n# 質問データを画像IDごとにグループ化し、辞書形式に変換\ntrain_question_df = train_question_df.groupby('id').apply(lambda df: df.to_dict(orient='list'))\ntrain_question_df = train_question_df.reset_index(name='qa') # グループ化結果を新しいカラム 'qa' に格納\n\n# 'qa' カラムから質問、選択肢、回答を抽出し、JSON文字列として格納\n# ensure_ascii=False で日本語がエスケープされないようにする\ntrain_question_df['question'] = train_question_df.qa.apply(lambda qa: json.dumps(qa['question'], ensure_ascii=False))\ntrain_question_df['choices'] = train_question_df.qa.apply(\n    lambda qa: json.dumps([x.tolist() for x in qa['choices']], ensure_ascii=False) # 選択肢はnumpy配列の場合があるのでリストに変換\n)\ntrain_question_df['answer'] = train_question_df.qa.apply(lambda qa: json.dumps(qa['answer'], ensure_ascii=False))\n\n# 学習データフレームに整形した質問データをマージ\ntrain_df = pd.merge(train_df, train_question_df, how='left', on='id')\n\n# 評価メトリック関数が扱いやすいように、質問・選択肢・回答をまとめた辞書カラムを作成\ntrain_df['multiple_choice_qa'] = train_df.apply(\n    lambda r: {\n        'question': json.loads(r.question),\n        'choices': json.loads(r.choices),\n        'answer': json.loads(r.answer)\n    },\n    axis=1,\n)\n\n# 最初の数行を表示してデータを確認\ntrain_df.head()","metadata":{"_uuid":"4262115f-a9a6-4f22-9091-faab4af75bf4","_cell_guid":"f5e24f42-3d7f-4293-9363-629d0117c52f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-10T16:58:26.105670Z","iopub.execute_input":"2025-05-10T16:58:26.106033Z","iopub.status.idle":"2025-05-10T16:58:27.790402Z","shell.execute_reply.started":"2025-05-10T16:58:26.106003Z","shell.execute_reply":"2025-05-10T16:58:27.789412Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-66fe83558dfb>:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  train_question_df = train_question_df.groupby('id').apply(lambda df: df.to_dict(orient='list'))\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       id                                        description  \\\n0  02d892                            a purple forest at dusk   \n1  0dcd2e              gray wool coat with a faux fur collar   \n2  1e9ac1                 a lighthouse overlooking the ocean   \n3  2b25db  burgundy corduroy pants with patch pockets and...   \n4  4e6a54                           orange corduroy overalls   \n\n                                                  qa  \\\n0  {'id': ['02d892', '02d892', '02d892', '02d892'...   \n1  {'id': ['0dcd2e', '0dcd2e', '0dcd2e', '0dcd2e'...   \n2  {'id': ['1e9ac1', '1e9ac1', '1e9ac1', '1e9ac1'...   \n3  {'id': ['2b25db', '2b25db', '2b25db', '2b25db'...   \n4  {'id': ['4e6a54', '4e6a54', '4e6a54', '4e6a54'...   \n\n                                            question  \\\n0  [\"What is the main setting of the image?\", \"Is...   \n1  [\"What color is the coat?\", \"What part of the ...   \n2  [\"Is there an ocean visible in the image?\", \"W...   \n3  [\"Are the pants yellow?\", \"Do the pants have p...   \n4  [\"What material is the item?\", \"Is a hat depic...   \n\n                                             choices  \\\n0  [[\"beach\", \"desert\", \"forest\", \"mountain\"], [\"...   \n1  [[\"blue\", \"brown\", \"gray\", \"red\"], [\"collar\", ...   \n2  [[\"no\", \"yes\"], [\"inside\", \"next to\", \"overloo...   \n3  [[\"no\", \"yes\"], [\"no\", \"yes\"], [\"no\", \"yes\"], ...   \n4  [[\"corduroy\", \"denim\", \"leather\", \"silk\"], [\"n...   \n\n                                  answer  \\\n0    [\"forest\", \"yes\", \"dusk\", \"purple\"]   \n1       [\"gray\", \"collar\", \"no\", \"wool\"]   \n2     [\"yes\", \"overlooking\", \"no\", \"no\"]   \n3          [\"no\", \"yes\", \"yes\", \"pants\"]   \n4  [\"corduroy\", \"no\", \"yes\", \"overalls\"]   \n\n                                  multiple_choice_qa  \n0  {'question': ['What is the main setting of the...  \n1  {'question': ['What color is the coat?', 'What...  \n2  {'question': ['Is there an ocean visible in th...  \n3  {'question': ['Are the pants yellow?', 'Do the...  \n4  {'question': ['What material is the item?', 'I...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>qa</th>\n      <th>question</th>\n      <th>choices</th>\n      <th>answer</th>\n      <th>multiple_choice_qa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>02d892</td>\n      <td>a purple forest at dusk</td>\n      <td>{'id': ['02d892', '02d892', '02d892', '02d892'...</td>\n      <td>[\"What is the main setting of the image?\", \"Is...</td>\n      <td>[[\"beach\", \"desert\", \"forest\", \"mountain\"], [\"...</td>\n      <td>[\"forest\", \"yes\", \"dusk\", \"purple\"]</td>\n      <td>{'question': ['What is the main setting of the...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0dcd2e</td>\n      <td>gray wool coat with a faux fur collar</td>\n      <td>{'id': ['0dcd2e', '0dcd2e', '0dcd2e', '0dcd2e'...</td>\n      <td>[\"What color is the coat?\", \"What part of the ...</td>\n      <td>[[\"blue\", \"brown\", \"gray\", \"red\"], [\"collar\", ...</td>\n      <td>[\"gray\", \"collar\", \"no\", \"wool\"]</td>\n      <td>{'question': ['What color is the coat?', 'What...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1e9ac1</td>\n      <td>a lighthouse overlooking the ocean</td>\n      <td>{'id': ['1e9ac1', '1e9ac1', '1e9ac1', '1e9ac1'...</td>\n      <td>[\"Is there an ocean visible in the image?\", \"W...</td>\n      <td>[[\"no\", \"yes\"], [\"inside\", \"next to\", \"overloo...</td>\n      <td>[\"yes\", \"overlooking\", \"no\", \"no\"]</td>\n      <td>{'question': ['Is there an ocean visible in th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2b25db</td>\n      <td>burgundy corduroy pants with patch pockets and...</td>\n      <td>{'id': ['2b25db', '2b25db', '2b25db', '2b25db'...</td>\n      <td>[\"Are the pants yellow?\", \"Do the pants have p...</td>\n      <td>[[\"no\", \"yes\"], [\"no\", \"yes\"], [\"no\", \"yes\"], ...</td>\n      <td>[\"no\", \"yes\", \"yes\", \"pants\"]</td>\n      <td>{'question': ['Are the pants yellow?', 'Do the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4e6a54</td>\n      <td>orange corduroy overalls</td>\n      <td>{'id': ['4e6a54', '4e6a54', '4e6a54', '4e6a54'...</td>\n      <td>[\"What material is the item?\", \"Is a hat depic...</td>\n      <td>[[\"corduroy\", \"denim\", \"leather\", \"silk\"], [\"n...</td>\n      <td>[\"corduroy\", \"no\", \"yes\", \"overalls\"]</td>\n      <td>{'question': ['What material is the item?', 'I...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## 2.画像生成","metadata":{}},{"cell_type":"markdown","source":"### 2.1 ビットマップ画像生成\nStable Diffusionを使用して、テキストプロンプトからビットマップ画像を生成します。\n\n画像は以下のハイパーパラメータに基づいて生成されます。\n- プロンプト（説明文）： 画像生成のためのテキストプロンプト。\n- ネガティブプロンプト： 生成を避けるべき要素を指定する\n- 推論ステップ数: 生成品質と速度のトレードオフ。多いほど高品質だが遅くなる。\n- ガイダンススケール: プロンプトへの忠実度。高いほどプロンプトに従うが、多様性が減る可能性。","metadata":{"_uuid":"e35c9af8-351c-4092-88e2-ea202f1b9670","_cell_guid":"517e1f19-bb4c-41cc-9e20-7e559b6ab287","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#| export\n\n# プロンプトに基づいてビットマップ画像を生成する関数\ndef generate_bitmap(prompt, negative_prompt=\"\", \n                    num_inference_steps=CFG.bitmap_num_inference_steps_default,\n                    guidance_scale=CFG.bitmap_guidance_scale_default):\n    \"\"\"\n    Stable Diffusionパイプラインを使用して画像を生成します。\n    \n    Returns:\n        PIL.Image: 生成されたビットマップ画像。\n    \"\"\"\n    image = pipe(\n        prompt=prompt,\n        negative_prompt=negative_prompt,\n        num_inference_steps=num_inference_steps,\n        guidance_scale=guidance_scale,\n    ).images[0] # 生成された画像のリストから最初の画像を取得\n\n    return image","metadata":{"_uuid":"016e16f1-ed6b-4684-983b-3605d6143be3","_cell_guid":"60d9280d-88cb-44a3-9a48-3bc0caa692ec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2 デモ\n学習データから一つの説明文を取り出し、プロンプトを組み立てて実際に画像を生成し、そのスコアを計算する。","metadata":{}},{"cell_type":"code","source":"# 以下のデモンストレーションで使用するプロンプト関連の変数をCFGから初期化\nprompt_prefix_demo = CFG.bitmap_prompt_prefix\nprompt_suffix_demo = CFG.bitmap_prompt_suffix\nnegative_prompt_demo = CFG.bitmap_negative_prompt","metadata":{"_uuid":"f403fc9d-8273-4468-ad6c-2e86b1d1c757","_cell_guid":"f8733497-fcbd-40a7-8c1c-a983e30dc756","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習データから1つのサンプルを取得して、その説明文を表示\nr = train_df.iloc[2] # 例として3番目のデータを使用\ndescription = r.description\nprint(f\"画像の説明文: {description}\")","metadata":{"_uuid":"9b14e724-2c19-4114-99d2-ab0a51369c00","_cell_guid":"6dc85789-a5e7-4a5e-9367-b59eef41d0dd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 上記の説明文と接頭辞・接尾辞を組み合わせてプロンプトを作成\nprompt = f'{prompt_prefix_demo} {description} {prompt_suffix_demo}'\nprint(f\"生成用プロンプト: {prompt}\")","metadata":{"_uuid":"5cc483d4-cd7e-45a6-b160-7d4208f1b96d","_cell_guid":"5a687d65-b716-4c4c-9648-be638e10b757","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 作成したプロンプトとネガティブプロンプトを使って画像を生成\n# generate_bitmap関数はCFGからデフォルトの推論ステップ数とガイダンススケールを使用\nimage = generate_bitmap(prompt, negative_prompt=negative_prompt_demo)\nimage # 生成された画像を表示 (Jupyter環境)","metadata":{"_uuid":"dab99943-08f2-4273-b324-6c79c7e0f97c","_cell_guid":"2c344156-7456-4e4a-b6d8-7cdcc68061a6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 生成されたビットマップ画像のスコアを計算\nbitmap_scores = bitmap_score_instance(r.multiple_choice_qa, image, random_seed=CFG.random_seed)\nprint(f\"ビットマップ画像のスコア: {bitmap_scores}\")","metadata":{"_uuid":"f54a6364-b4c7-455b-8b75-06a3d70ec310","_cell_guid":"1ca90047-bdac-4f4e-9785-e2d45ebdecaf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.画像からSVGへの変換","metadata":{}},{"cell_type":"markdown","source":"### 画像 -> SVGへ変換するための様々な工夫\nこのセクションでは、生成されたビットマップ画像をSVG形式に変換する処理を実装します。\n\n提出するSVGにはファイルサイズ制限があるため、単純にビットマップ画像をSVGに変換するだけでなく、ファイルサイズを削減する工夫を施します。\n\n主な処理の流れは以下の通りです：\n1. 色の量子化: 画像の色を量子化（k-means法）して、主要な色のみを保持することで画像の色数を減らします。\n2. 輪郭抽出: 量子化された画像から、各色の領域の輪郭を検出します。\n3. 輪郭の単純化: 検出された輪郭をポリゴンで近似し、頂点数を減らしてSVGファイルのサイズを削減します。\n4. 特徴の階層化と選択: 輪郭（ポリゴン）を面積や位置などの重要度でソートし、SVGのファイルサイズ制限内でできるだけ多くの情報を含むようにポリゴンを選択・単純化します。\n5. 画像のリサイズ：必要に応じて画像をリサイズします。\n6. SVG生成: 選択されたポリゴンをSVG要素として記述し、SVGファイルを構築します。","metadata":{"_uuid":"ec0fb08a-006c-434a-bee9-f7a1b24d0962","_cell_guid":"8f8dd360-2840-4d08-80ee-4c940d09df7c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#| export\n\n# 16進数カラーコードを短縮表現に変換する関数\n# 例: #FF00AA -> #F0A (R,G,Bがそれぞれ17の倍数の場合)\ndef compress_hex_color(hex_color):\n    \"\"\"16進数のカラーコードを可能な限り短い表現に変換します（例: #aabbcc -> #abc）。\"\"\"\n    r, g, b = int(hex_color[1:3], 16), int(hex_color[3:5], 16), int(hex_color[5:7], 16)\n    if r % 17 == 0 and g % 17 == 0 and b % 17 == 0:\n        # 各RGB値が17の倍数の場合、1桁の16進数で表現可能\n        return f'#{r//17:x}{g//17:x}{b//17:x}'\n    return hex_color\n\n# 画像から階層的な特徴（色ごとのポリゴン）を抽出する関数\ndef extract_features_by_scale(img_np, num_colors=16): # num_colorsはbitmap_to_svg_layeredから渡される\n    \"\"\"\n    画像から色ごとの輪郭を抽出し、重要度に基づいてソートされた特徴のリストを返します。\n    Args:\n        img_np (np.ndarray): 入力画像 (NumPy配列)。\n        num_colors (int): 量子化する色の数。\n    Returns:\n        list: 抽出されたポリゴンの特徴 (座標、色、面積、重要度など) のリスト。\n    \"\"\"\n    # 画像がグレースケールの場合、RGBに変換\n    if len(img_np.shape) == 3 and img_np.shape[2] > 1:\n        img_rgb = img_np\n    else:\n        img_rgb = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n\n    height, width = img_rgb.shape[:2]\n\n    # k-means法による色の量子化\n    pixels = img_rgb.reshape(-1, 3).astype(np.float32)\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) # k-meansの停止条件\n    _, labels, centers = cv2.kmeans(pixels, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n    \n    palette = centers.astype(np.uint8) # 量子化された色のパレット\n    quantized_image = palette[labels.flatten()].reshape(img_rgb.shape) # 量子化された画像\n\n    hierarchical_features = [] # 抽出された特徴を格納するリスト\n\n    # 色の出現頻度に基づいてソート\n    unique_labels, counts = np.unique(labels, return_counts=True)\n    sorted_indices = np.argsort(-counts) # 降順ソート\n    sorted_colors = [palette[i] for i in sorted_indices]\n\n    center_x, center_y = width / 2, height / 2 # 画像中心\n\n    # ソートされた各色について輪郭を抽出\n    for color_val in sorted_colors:\n        # 特定の色に対応するマスクを作成\n        color_mask = cv2.inRange(quantized_image, color_val, color_val)\n        \n        # マスクから輪郭を検出\n        contours, _ = cv2.findContours(color_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        contours = sorted(contours, key=cv2.contourArea, reverse=True) # 面積でソート\n\n        hex_color_str = compress_hex_color(f'#{color_val[0]:02x}{color_val[1]:02x}{color_val[2]:02x}')\n\n        color_specific_features = []\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            # 小さすぎる輪郭は無視 (CFGから閾値を取得)\n            if area < CFG.svg_contour_min_area:\n                continue\n\n            # 輪郭のモーメントを計算して中心座標を取得\n            m = cv2.moments(contour)\n            if m[\"m00\"] == 0: continue # 面積0の輪郭はスキップ\n            cx = int(m[\"m10\"] / m[\"m00\"])\n            cy = int(m[\"m01\"] / m[\"m00\"])\n\n            # 画像中心からの距離 (正規化)\n            dist_from_center = np.sqrt(((cx - center_x) / width)**2 + ((cy - center_y) / height)**2)\n\n            # 輪郭を単純化 (Douglas-Peuckerアルゴリズム)\n            epsilon = CFG.svg_approx_poly_dp_epsilon_factor * cv2.arcLength(contour, True) # epsilon係数はCFGから取得\n            approx_poly = cv2.approxPolyDP(contour, epsilon, True)\n\n            # ポリゴンの頂点座標を文字列に変換 (小数点以下1桁)\n            points_str = \" \".join([f\"{pt[0][0]:.1f},{pt[0][1]:.1f}\" for pt in approx_poly])\n\n            # 特徴の重要度を計算 (面積、中心からの近さ、複雑さの逆数)\n            importance = (area * (1 - dist_from_center) * (1 / (len(approx_poly) + 1e-6))) # ゼロ除算を避ける\n\n            color_specific_features.append({\n                'points': points_str,\n                'color': hex_color_str,\n                'area': area,\n                'importance': importance,\n                'point_count': len(approx_poly),\n                'original_contour': approx_poly # 適応的単純化のために元の輪郭を保存\n            })\n        \n        # この色に関する特徴を重要度でソート\n        color_specific_features.sort(key=lambda x: x['importance'], reverse=True)\n        hierarchical_features.extend(color_specific_features)\n\n    # 全ての特徴を重要度で最終ソート\n    hierarchical_features.sort(key=lambda x: x['importance'], reverse=True)\n    return hierarchical_features\n\n# ポリゴンを単純化する関数\ndef simplify_polygon(points_str, simplification_level):\n    \"\"\"\n    ポリゴンの頂点座標文字列を、指定されたレベルに応じて単純化します。\n    Args:\n        points_str (str): スペース区切りの \"x,y\" 形式の頂点座標文字列。\n        simplification_level (int): 単純化のレベル (0:変更なし, 1:小数点1桁, 2:整数, 3:頂点削減)。\n    Returns:\n        str: 単純化された頂点座標文字列。\n    \"\"\"\n    if simplification_level == 0:\n        return points_str\n\n    points_list = points_str.split()\n\n    if simplification_level == 1: # レベル1: 小数点以下1桁に丸める\n        return \" \".join([f\"{float(p.split(',')[0]):.1f},{float(p.split(',')[1]):.1f}\" for p in points_list])\n    \n    if simplification_level == 2: # レベル2: 整数に丸める\n        return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in points_list])\n\n    if simplification_level == 3: # レベル3: 頂点数を減らす（1つおきに点を保持、最低3点は確保）\n        if len(points_list) <= 4:\n            # 点が4つ以下の場合、整数に丸めるだけ\n            return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in points_list])\n        else:\n            # 約半分の点を保持するが、少なくとも3点は維持する\n            step = min(2, len(points_list) // 3) # 3点未満にならないよう調整\n            reduced_points = [points_list[i] for i in range(0, len(points_list), step)]\n            if len(reduced_points) < 3 and len(points_list) >=3: # 元が3点以上なら最低3点\n                 reduced_points = points_list[:3]\n            if points_list[-1] not in reduced_points and reduced_points: # 最後の点は必ず含める\n                reduced_points.append(points_list[-1])\n            return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in reduced_points])\n    \n    return points_str # 未定義のレベルの場合は変更なし\n\n# ビットマップ画像を階層化された特徴抽出を用いてSVGに変換する関数\ndef bitmap_to_svg_layered(image, \n                         max_size_bytes=CFG.svg_max_size_bytes, \n                         resize=CFG.svg_resize, \n                         target_size=CFG.svg_target_size,\n                         adaptive_fill=CFG.svg_adaptive_fill, \n                         num_colors=CFG.svg_num_colors_default):\n    \"\"\"\n    ビットマップ画像をSVG形式に変換します。ファイルサイズ制限内で最適化を行います。\n    Args:\n        image (PIL.Image): 入力画像。\n        max_size_bytes (int): SVGの最大許容バイト数。\n        resize (bool): 処理前に画像をリサイズするかどうか。\n        target_size (tuple): リサイズする場合のターゲットサイズ (幅, 高さ)。\n        adaptive_fill (bool): 利用可能なスペースを適応的に埋めるかどうか。\n        num_colors (int, optional): 量子化する色の数。Noneの場合、画像のサイズに基づいて適応的に決定。\n    Returns:\n        str: SVG形式の文字列。\n    \"\"\"\n    # num_colorsが指定されていない場合、画像のピクセル数に基づいて適応的に色数を決定\n    if num_colors is None:\n        pixel_count = (target_size[0] * target_size[1]) if resize else (image.size[0] * image.size[1])\n        \n        if pixel_count < CFG.svg_num_colors_small_image_threshold:\n            num_colors = CFG.svg_num_colors_for_small_image\n        elif pixel_count < CFG.svg_num_colors_medium_image_threshold:\n            num_colors = CFG.svg_num_colors_for_medium_image\n        else:\n            num_colors = CFG.svg_num_colors_for_large_image\n    \n    original_size = image.size\n    if resize:\n        image = image.resize(target_size, Image.LANCZOS) # LANCZOSでリサンプル\n    \n    img_np_array = np.array(image)\n    current_height, current_width = img_np_array.shape[:2]\n\n    # 背景色を画像の平均色で決定 (RGB画像の場合)\n    if len(img_np_array.shape) == 3 and img_np_array.shape[2] == 3:\n        avg_bg_color_val = np.mean(img_np_array, axis=(0,1)).astype(int)\n        bg_hex_color_str = compress_hex_color(f'#{avg_bg_color_val[0]:02x}{avg_bg_color_val[1]:02x}{avg_bg_color_val[2]:02x}')\n    else: # グレースケール等の場合は白背景\n        bg_hex_color_str = '#fff' \n\n    # SVGヘッダーと背景。viewBoxは処理後の画像の寸法、width/heightは元の画像の寸法\n    orig_width, orig_height = original_size\n    svg_header_str = f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{orig_width}\" height=\"{orig_height}\" viewBox=\"0 0 {current_width} {current_height}\">\\n'\n    svg_bg_rect_str = f'<rect width=\"{current_width}\" height=\"{current_height}\" fill=\"{bg_hex_color_str}\"/>\\n'\n    svg_base_content = svg_header_str + svg_bg_rect_str\n    svg_footer_str = '</svg>'\n\n    base_content_size = len((svg_base_content + svg_footer_str).encode('utf-8'))\n    available_bytes_for_features = max_size_bytes - base_content_size\n\n    # 画像から特徴（ポリゴン）を抽出\n    extracted_features = extract_features_by_scale(img_np_array, num_colors=num_colors)\n\n    # 適応的フィルを使用しない場合: 単純に特徴を追加していく\n    if not adaptive_fill:\n        current_svg_content = svg_base_content\n        for feature_item in extracted_features:\n            feature_svg_element = f'<polygon points=\"{feature_item[\"points\"]}\" fill=\"{feature_item[\"color\"]}\" />\\n'\n            if len((current_svg_content + feature_svg_element + svg_footer_str).encode('utf-8')) > max_size_bytes:\n                break # サイズ制限を超えたら終了\n            current_svg_content += feature_svg_element\n        current_svg_content += svg_footer_str\n        return current_svg_content\n\n    # 適応的フィルを使用する場合: 2パスアプローチで単純化レベルを調整しながら特徴を追加\n    # 各特徴について、異なる単純化レベルでのSVG要素サイズを事前計算\n    feature_element_sizes = []\n    for feature_item in extracted_features:\n        feature_element_sizes.append({\n            'original': len(f'<polygon points=\"{feature_item[\"points\"]}\" fill=\"{feature_item[\"color\"]}\" />\\n'.encode('utf-8')),\n            'level1': len(f'<polygon points=\"{simplify_polygon(feature_item[\"points\"], 1)}\" fill=\"{feature_item[\"color\"]}\" />\\n'.encode('utf-8')),\n            'level2': len(f'<polygon points=\"{simplify_polygon(feature_item[\"points\"], 2)}\" fill=\"{feature_item[\"color\"]}\" />\\n'.encode('utf-8')),\n            'level3': len(f'<polygon points=\"{simplify_polygon(feature_item[\"points\"], 3)}\" fill=\"{feature_item[\"color\"]}\" />\\n'.encode('utf-8'))\n        })\n\n    current_svg_content = svg_base_content\n    bytes_used_so_far = base_content_size\n    added_feature_indices = set()\n\n    # パス1: 最も重要な特徴を元の品質で追加\n    for i, feature_item in enumerate(extracted_features):\n        feature_svg_element = f'<polygon points=\"{feature_item[\"points\"]}\" fill=\"{feature_item[\"color\"]}\" />\\n'\n        current_feature_size = feature_element_sizes[i]['original']\n        if bytes_used_so_far + current_feature_size <= max_size_bytes:\n            current_svg_content += feature_svg_element\n            bytes_used_so_far += current_feature_size\n            added_feature_indices.add(i)\n\n    # パス2: 残りの特徴を単純化レベルを上げながら追加\n    for simpl_level in range(1, 4): # 単純化レベル 1, 2, 3\n        for i, feature_item in enumerate(extracted_features):\n            if i in added_feature_indices: continue # 既に追加済みならスキップ\n\n            current_feature_size = feature_element_sizes[i][f'level{simpl_level}']\n            if bytes_used_so_far + current_feature_size <= max_size_bytes:\n                simplified_points = simplify_polygon(feature_item[\"points\"], simpl_level)\n                feature_svg_element = f'<polygon points=\"{simplified_points}\" fill=\"{feature_item[\"color\"]}\" />\\n'\n                current_svg_content += feature_svg_element\n                bytes_used_so_far += current_feature_size\n                added_feature_indices.add(i)\n    \n    current_svg_content += svg_footer_str\n\n    # 最終的なサイズチェック。万が一超過していたら、背景のみのSVGを返す\n    final_svg_size = len(current_svg_content.encode('utf-8'))\n    if final_svg_size > max_size_bytes:\n        return f'<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 {current_width} {current_height}\"><rect width=\"{current_width}\" height=\"{current_height}\" fill=\"{bg_hex_color_str}\"/></svg>'\n    \n    # print(f\"SVG size: {final_svg_size} bytes, Utilization: {(final_svg_size / max_size_bytes) * 100:.2f}%\")\n    return current_svg_content","metadata":{"_uuid":"841f8d6a-9c19-437c-9c42-0102ed9c7f60","_cell_guid":"d09bc529-673a-4e33-bfd0-3c1970669c9c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2 デモ\n作成されたSVGを表示し、そのスコアを計算する。","metadata":{}},{"cell_type":"code","source":"# bitmap_to_svg_layered関数はCFGからデフォルト引数を使用\nsvg_content = bitmap_to_svg_layered(image)\nSVG(svg_content) # 生成されたSVGを表示 (Jupyter環境)","metadata":{"_uuid":"6b96189e-a987-4999-9110-75d93448a179","_cell_guid":"272bd48f-3539-4610-bae6-20e1f3d7c083","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 生成されたSVGのスコアを計算\n# random_seedはCFGから取得\nsvg_scores = metric.score_instance(r.multiple_choice_qa, svg_content, random_seed=CFG.random_seed)\nprint(f\"SVG画像のスコア: {svg_scores}\")","metadata":{"_uuid":"f9e07a7a-f354-478f-aba9-45e7e670a22e","_cell_guid":"1ee6a12c-266d-44f7-8fcc-ffca077eda4b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 先ほど生成したSVGの美的スコアとOCRスコアを取得\naesthetic_score_val, ocr_score_val = get_aes_and_ocr_score(svg_content)\nprint(f\"美的スコア: {aesthetic_score_val}, OCRスコア: {ocr_score_val}\")","metadata":{"_uuid":"b0d8bf83-f0a3-487e-9ada-c924d9b87dc0","_cell_guid":"5f7f6b0f-142f-4c26-adc8-ee5520980aec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.提出パッケージの実装","metadata":{}},{"cell_type":"markdown","source":"### 4.1 パッケージのModelクラスを実装\n- **`Model`クラス**:\n    - このクラスは、画像生成からSVG変換、そしてスコア最適化までの一連の処理をカプセル化します。\n    - `__init__`: プロンプトの接頭辞・接尾辞、Stable Diffusionの推論ステップ数・ガイダンススケール、最適化のための試行回数などを`CFG`から設定します。\n    - `gen_bitmap`: `Model`クラス固有のパラメータ設定でビットマップ画像を生成します。\n    - `predict`メソッドは、与えられた説明文から最適なSVGを生成することを目指します。\n        - `predict_impl`:\n            1. 説明文からビットマップ画像を生成 (`gen_bitmap`)。\n            2. 生成したビットマップをSVGに変換 (`bitmap_to_svg_layered`)。\n            3. SVGの美的スコアとOCRスコアを取得 (`get_aes_and_ocr_score`)。\n            4. 美的スコアとOCRスコアの**積**を最終スコアとして計算。\n            5. 上記1～4を`model_num_attempt`回繰り返し、最終スコアが最も高かったSVGとその元ビットマップを返します。\n        - `predict`: `predict_impl`を呼び出し、最終的に最適と判断されたSVG文字列のみを返します。","metadata":{"_uuid":"a83a19e8-d18d-4269-8c6c-4fd1065d23a2","_cell_guid":"f77dbccd-163b-40a5-ba2e-fadb54a63aa8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#| export\n\nclass Model:\n    def __init__(self):\n        # CFGからモデルのデフォルト設定を初期化\n        self.default_svg = CFG.model_default_svg\n        self.prompt_prefix = CFG.model_prompt_prefix\n        self.prompt_suffix = CFG.model_prompt_suffix\n        self.negative_prompt = CFG.model_negative_prompt\n\n        self.num_inference_steps = CFG.model_num_inference_steps # 画像生成時の推論ステップ数\n        self.guidance_scale = CFG.model_guidance_scale           # 画像生成時のガイダンススケール\n        self.num_attempt = CFG.model_num_attempt                 # 最適なSVGを見つけるための試行回数\n\n    # 説明文に基づいてビットマップ画像を生成する内部メソッド\n    def gen_bitmap(self, description_text):\n        # クラス固有のプロンプト接頭辞・接尾辞を使用\n        full_prompt = f'{self.prompt_prefix} {description_text} {self.prompt_suffix}'\n        # クラス固有の推論ステップ数とガイダンススケールでビットマップを生成\n        bitmap_image = generate_bitmap(full_prompt, self.negative_prompt, \n                                      self.num_inference_steps, self.guidance_scale)\n        return bitmap_image\n\n    # プロンプト（説明文）からSVGを生成する内部実装メソッド\n    # 複数回試行し、美的スコアとOCRスコアの積が最も高いものを選択\n    def predict_impl(self, description_prompt: str) -> tuple[str, Image.Image | None]:\n        \"\"\"\n        説明文プロンプトから最適なSVG文字列と対応するビットマップ画像を生成します。\n        Args:\n            description_prompt (str): 画像の内容を表す説明文。\n        Returns:\n            tuple: (最適なSVG文字列, 対応するビットマップ画像)\n        \"\"\"\n        best_combined_score = 0.0\n        best_svg_output = None\n        best_generated_image = None\n        \n        for _ in range(self.num_attempt): # 設定された試行回数だけ繰り返す\n            # 1. ビットマップ画像を生成\n            current_bitmap = self.gen_bitmap(description_prompt)\n            \n            # 2. ビットマップをSVGに変換 (bitmap_to_svg_layeredはCFG由来のデフォルトパラメータを使用)\n            current_svg = bitmap_to_svg_layered(current_bitmap)\n            \n            # 3. SVGの美的スコアとOCRスコアを取得 (get_aes_and_ocr_scoreはCFG由来のデフォルトパラメータを使用)\n            aes_score, ocr_s = get_aes_and_ocr_score(current_svg)\n            \n            # 4. スコアを評価 (美的スコア * OCRスコア)\n            current_score = aes_score * ocr_s\n            \n            if current_score >= best_combined_score: # より良いスコアなら更新\n                best_combined_score = current_score\n                best_svg_output = current_svg\n                best_generated_image = current_bitmap\n                print(f'スコア更新: {best_combined_score:.4f} (AES: {aes_score:.4f}, OCR: {ocr_s:.4f})')\n\n        if best_svg_output is None: # 一度も有効なSVGが生成されなかった場合\n            best_svg_output = self.default_svg # デフォルトSVGを返す\n            best_generated_image = None # この場合、対応するビットマップはない\n\n        return best_svg_output, best_generated_image\n\n    # プロンプト（説明文）からSVGを生成する公開メソッド\n    def predict(self, description_prompt: str) -> str:\n        \"\"\"\n        説明文プロンプトから最適なSVG文字列を生成します。\n        Args:\n            description_prompt (str): 画像の内容を表す説明文。\n        Returns:\n            str: 最適なSVG文字列。\n        \"\"\"\n        svg_result, _ = self.predict_impl(description_prompt) # ビットマップは返さない\n        return svg_result","metadata":{"_uuid":"75abae8f-a8cb-48d5-a8b0-80af2c15acce","_cell_guid":"36015be7-ea4d-4124-8cf6-bc855716428d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.2 デモ\n作成されたSVGを表示し、そのスコアを計算する。","metadata":{}},{"cell_type":"code","source":"# Modelクラスのインスタンスを作成\nmodel = Model()","metadata":{"_uuid":"cdbe83f7-ff47-4ad2-9735-277fce5e817b","_cell_guid":"ead19f8c-2f62-4828-abe3-7b123bd9a2a7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modelクラスのpredictメソッドを使用してSVGを生成\n# `description`変数は以前のセルで定義されたものを使用\nsvg_output_from_model = model.predict(description)\nSVG(svg_output_from_model) # 作成されたSVGを表示","metadata":{"_uuid":"18ea5eba-fd64-4769-b829-08c6cee5a6fc","_cell_guid":"b1e15117-229d-4e1f-b7ce-a2b1711b4eb0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SVGのスコアを計算\nmodel_svg_scores = metric.score_instance(r.multiple_choice_qa, svg_output_from_model, random_seed=CFG.random_seed)# `r`変数は以前のセルで定義されたサンプルデータ。random_seedはCFGから取得\nprint(f\"Model生成SVGのスコア: {model_svg_scores}\")","metadata":{"_uuid":"a854e51d-5e1a-4b20-94a5-cc3711b51169","_cell_guid":"41c0a4b7-60ae-49e5-8606-b9a07f75fafe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.学習データセットを用いた検証\n- 学習データセット全体に対して作成したパッケージを適用し、生成されたSVGの平均スコアを計算します。\n- これにより、リーダーボード（LB）でのスコアをある程度予測することができます。\n- 各サンプルについて、元のビットマップ画像のスコアと、生成されたSVGのスコアの両方を評価し比較します。","metadata":{"_uuid":"a4c6ddd5-6915-4b1a-97b9-8a539a166fda","_cell_guid":"e2efc751-3dab-46cc-8d97-30f94f65a276","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Jupyter Notebookでmatplotlibのプロットをインライン表示するためのマジックコマンド\n%matplotlib inline　","metadata":{"_uuid":"1a924b2b-a732-4c78-a59a-2bc930b72e7b","_cell_guid":"3f43dfba-1039-4a69-bd2a-31e871062f44","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm #提出パッケージには含まれないため、ここでimport\ntqdm.pandas() # pandasのapply操作でプログレスバーを表示できるようにする","metadata":{"_uuid":"06b182ce-bc19-49c4-b971-216e1397e9c9","_cell_guid":"44c0a0aa-0565-40f5-8a9f-88fc64c38691","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習データフレームの先頭を表示して再確認\ntrain_df.head()","metadata":{"_uuid":"c30831d9-8e6d-4fd6-b093-13de48a5c3d3","_cell_guid":"d1628fb1-7942-4f7c-ba8c-376e6f5096d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習データセットの各説明文に対してmodel.predict_implを実行し、結果 (SVGとビットマップ) を保存\ntrain_df['raw_res'] = train_df.description.progress_apply(model.predict_impl)","metadata":{"_uuid":"450bb92a-c698-4334-920a-db63cd49ac7e","_cell_guid":"41395443-0358-4d29-ae4e-71b2f522e61a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 'raw_res' カラムからSVG文字列とビットマップ画像をそれぞれ別のカラムに展開\ntrain_df['svg'] = train_df.raw_res.apply(lambda x: x[0])\ntrain_df['bitmap'] = train_df.raw_res.apply(lambda x: x[1])","metadata":{"_uuid":"dad83d57-1e7b-4895-911a-0027c64a4b06","_cell_guid":"023a8de1-974d-456c-9415-d2cfddb898a9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 各ビットマップ画像のスコアを計算\n# progress_applyで処理の進捗を表示\n# random_seedはCFGから取得\ntrain_df['bitmap_score'] = train_df.progress_apply(\n    lambda r: bitmap_score_instance(r.multiple_choice_qa, r.bitmap, random_seed=CFG.random_seed) if r.bitmap else None, # ビットマップが存在しない場合はNone\n    axis=1,\n)","metadata":{"_uuid":"3ce4cd50-4b7b-438c-be27-4052ede69d41","_cell_guid":"be3fd15e-93f2-4b6b-bac7-dd9ed2709023","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 各SVG画像のスコアを計算\n# progress_applyで処理の進捗を表示\n# random_seedはCFGから取得\ntrain_df['svg_score'] = train_df.progress_apply(\n    lambda r: metric.score_instance(r.multiple_choice_qa, r.svg, random_seed=CFG.random_seed),\n    axis=1,\n)","metadata":{"_uuid":"2afbf65d-8a2b-4184-b503-ff587f9337be","_cell_guid":"acd4a088-f872-4262-b7b2-6c7525ff041f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習データセットの各サンプルについて、ビットマップ画像とSVG画像を並べて表示し、それぞれのスコアを表示\nfor r in train_df.itertuples():\n    # ビットマップのスコア詳細を取得 (存在する場合のみ)\n    if r.bitmap and r.bitmap_score:\n        b_score = r.bitmap_score.get('competition_score', 0)\n        b_vqa = r.bitmap_score.get('vqa_score', 0)\n        b_ocr = r.bitmap_score.get('ocr_score', 0)\n        b_aesthetic = r.bitmap_score.get('aesthetic_score', 0)\n    else: # ビットマップやスコアが存在しない場合\n        b_score, b_vqa, b_ocr, b_aesthetic = 0, 0, 0, 0\n\n    # SVGのスコア詳細を取得\n    s_score = r.svg_score.get('competition_score', 0)\n    s_vqa = r.svg_score.get('vqa_score', 0)\n    s_ocr = r.svg_score.get('ocr_score', 0)\n    s_aesthetic = r.svg_score.get('aesthetic_score', 0)\n\n    plt.figure(figsize=(12, 6))\n    plt.suptitle(f\"説明: {r.description}\", y=0.93, fontsize=10) # yとfontsize調整\n\n    # ビットマップ画像表示\n    plt.subplot(1, 2, 1)\n    if r.bitmap:\n        plt.imshow(np.array(r.bitmap))\n    else: # ビットマップがない場合はテキスト表示\n        plt.text(0.5, 0.5, \"No Bitmap Generated\", ha='center', va='center')\n    plt.axis('off')\n    plt.title(f'bitmap: score={b_score:.2f}\\nVQA={b_vqa:.2f}, OCR={b_ocr:.2f}, aes={b_aesthetic:.2f}', fontsize=9)\n\n    # SVG画像表示 (PNGに変換して表示)\n    plt.subplot(1, 2, 2)\n    try:\n        plt.imshow(metric.svg_to_png(r.svg))\n    except Exception as e: # SVG変換エラーの場合\n        plt.text(0.5, 0.5, f\"SVG Display Error:\\n{e}\", ha='center', va='center', fontsize=8)\n\n    plt.axis('off')\n    plt.title(f'SVG: score={s_score:.2f}\\nVQA={s_vqa:.2f}, OCR={s_ocr:.2f}, aes={s_aesthetic:.2f}', fontsize=9)\n    \n    plt.tight_layout(rect=[0, 0, 1, 0.9]) # suptitleとの重なりを避ける\n    plt.show()","metadata":{"_uuid":"046d8586-d54c-4a64-9337-d82a57108ed0","_cell_guid":"3ec43c2a-7309-4403-8633-bf6130283bcf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ビットマップスコアの平均を計算して表示 (Noneを除外)\nvalid_bitmap_scores = [s for s in train_df['bitmap_score'].tolist() if s is not None]\nif valid_bitmap_scores:\n    mean_bitmap_score = pd.DataFrame(valid_bitmap_scores).mean(axis=0)\n    print(\"平均ビットマップスコア:\")\n    print(mean_bitmap_score)\nelse:\n    print(\"有効なビットマップスコアがありません。\")","metadata":{"_uuid":"d6611cd8-e308-46e5-85d4-372f4d531971","_cell_guid":"4a17c6a3-ce44-49f7-bcdd-d5524eca3788","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SVGスコアの平均を計算して表示 (Noneを除外)\nvalid_svg_scores = [s for s in train_df['svg_score'].tolist() if s is not None]\nif valid_svg_scores:\n    mean_svg_score = pd.DataFrame(valid_svg_scores).mean(axis=0)\n    print(\"平均SVGスコア:\")\n    print(mean_svg_score)\nelse:\n    print(\"有効なSVGスコアがありません。\")","metadata":{"_uuid":"ace6f834-7a79-4e0a-84ee-b8484f16e3f2","_cell_guid":"43d0091a-ec50-43e0-bdd8-8dbb55a0eb5e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 最終的な平均コンペティションスコアを表示\nif valid_bitmap_scores:\n    print(f'ビットマップ画像の平均コンペティションスコア: {mean_bitmap_score.competition_score if \"competition_score\" in mean_bitmap_score else \"N/A\"}')\nif valid_svg_scores:\n    print(f'最終的なSVG画像の平均コンペティションスコア: {mean_svg_score.competition_score if \"competition_score\" in mean_svg_score else \"N/A\"}')","metadata":{"_uuid":"665da158-ef96-4421-8494-a012793e2d53","_cell_guid":"2416fba3-fac5-497f-a04f-5c7d90ae4a8b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}